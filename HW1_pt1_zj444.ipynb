{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "py36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "HW1_pt1_zj444.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiangzian96/DS1012/blob/master/HW1_pt1_zj444.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Z8eeN5IW9q",
        "colab_type": "text"
      },
      "source": [
        "# Part 1.\n",
        "\n",
        "The deadline for Part 1 is **1:30 pm Feb 6th, 2020**.   \n",
        "You should submit a `.ipynb` file with your solutions to NYU Classes.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this part we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZd0LJzbISPd",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvGErs2oHkWU",
        "colab_type": "code",
        "outputId": "9b12fd41-abbb-471d-9083-bdab6746d8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-08 01:32:54--  https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.203.101, 74.125.203.102, 74.125.203.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/vk0s99ate52jrai83kfhgdmqrhprmrii/1581125400000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-08 01:32:55--  https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/vk0s99ate52jrai83kfhgdmqrhprmrii/1581125400000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download\n",
            "Resolving doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)... 108.177.125.132, 2404:6800:4008:c01::84\n",
            "Connecting to doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)|108.177.125.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503663 (492K) [text/csv]\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "\rspam.csv              0%[                    ]       0  --.-KB/s               \rspam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2020-02-08 01:32:55 (144 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHV1lUwtH-n",
        "colab_type": "code",
        "outputId": "24659f19-446d-4fea-e5e0-1817b45bcd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  spam.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXVQCF-ovo4G",
        "colab_type": "text"
      },
      "source": [
        "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiKE89v0zMiY",
        "colab_type": "code",
        "outputId": "8e48463d-8cb2-42cb-bf9a-e117786132bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
        "# 1 - spam, 0 - ham\n",
        "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
        "df.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v1                                                 v2\n",
              "0   0  Go until jurong point, crazy.. Available only ...\n",
              "1   0                      Ok lar... Joking wif u oni...\n",
              "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   0  U dun say so early hor... U c already then say...\n",
              "4   0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQhTzrCv-Nk",
        "colab_type": "text"
      },
      "source": [
        "Your task is to split the data to train/dev/test. Make sure that each row appears only in one of the splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga5Qydpw-gdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.15 for val, 0.15 for test, 0.7 for train\n",
        "val_size = int(df.shape[0] * 0.15)\n",
        "test_size = int(df.shape[0] * 0.15)\n",
        "\n",
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "shuffle = np.arange(df.shape[0])\n",
        "np.random.shuffle(shuffle)\n",
        "train_size = df.shape[0] - val_size - test_size\n",
        "labels = df[\"v1\"].to_numpy()\n",
        "\n",
        "train_texts, train_labels = df[\"v2\"].iloc[:train_size], labels[:train_size]\n",
        "val_texts, val_labels     = df[\"v2\"].iloc[train_size:train_size+val_size], labels[train_size:train_size+val_size]\n",
        "test_texts, test_labels   = df[\"v2\"].iloc[-test_size:], labels[-test_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGyHG4lBISP2",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing\n",
        "\n",
        "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
        "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
        "\n",
        "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
        "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
        "\n",
        "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYcD7OPWdv3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "793EFaQYhHeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7e89298f-cfab-4dfb-9962-6fc4223b9691"
      },
      "source": [
        "def preprocess_data(data):\n",
        "    # This function should return a list of lists of preprocessed tokens for each message\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    preprocessed_data = []\n",
        "\n",
        "    for sent in tqdm(data):\n",
        "      temp = []\n",
        "      doc = nlp(sent)\n",
        "      for token in doc:\n",
        "        temp.append(token.text.lower())\n",
        "\n",
        "      preprocessed_data.append(temp)\n",
        "    return preprocessed_data\n",
        "\n",
        "train_data = preprocess_data(train_texts)\n",
        "val_data = preprocess_data(val_texts)\n",
        "test_data = preprocess_data(test_texts)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3902/3902 [00:46<00:00, 84.78it/s]\n",
            "100%|██████████| 835/835 [00:09<00:00, 85.12it/s]\n",
            "100%|██████████| 835/835 [00:09<00:00, 85.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM2qpOKpjVbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "class Vectorizer():\n",
        "    def __init__(self, max_features):\n",
        "        self.max_features = max_features\n",
        "        self.vocab_list = None\n",
        "        self.token_to_index = None\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
        "        # Create a token indexer, self.token_to_index, that will return index of the token in self.vocab\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        all_tokens = []\n",
        "        UNK_IDX = 0\n",
        "        for sent in tqdm(dataset):\n",
        "          for token in sent:\n",
        "            all_tokens.append(token)\n",
        "        token_counter = Counter(all_tokens)\n",
        "        vocab, count = zip(*token_counter.most_common(self.max_features))\n",
        "        self.token_to_index = dict(zip(vocab, range(1,1+len(vocab)))) \n",
        "        self.token_to_index[\"<unk>\"] = UNK_IDX\n",
        "        self.vocab_list = [\"<unk>\"]+ list(vocab)\n",
        "\n",
        "    def transform(self, dataset):\n",
        "        # This function transforms text dataset into a matrix, data_matrix\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
        "        for i in tqdm(range(len(dataset))):\n",
        "          sent = dataset[i]\n",
        "          for token in sent:\n",
        "            if token in self.token_to_index:\n",
        "              j = self.token_to_index[token]\n",
        "            else:\n",
        "              j = self.token_to_index[\"<unk>\"]\n",
        "            data_matrix[i,j] += 1\n",
        "        return data_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXMrZXlZjcH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31e186ec-49f7-4dfb-c94f-9a749e7a1465"
      },
      "source": [
        "max_features = 10000 \n",
        "vectorizer = Vectorizer(max_features=max_features)\n",
        "vectorizer.fit(train_data)\n",
        "X_train = vectorizer.transform(train_data)\n",
        "X_val = vectorizer.transform(val_data)\n",
        "X_test = vectorizer.transform(test_data)\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "vocab = vectorizer.vocab_list\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3902/3902 [00:00<00:00, 251184.45it/s]\n",
            "100%|██████████| 3902/3902 [00:00<00:00, 56332.52it/s]\n",
            "100%|██████████| 835/835 [00:00<00:00, 46820.19it/s]\n",
            "100%|██████████| 835/835 [00:00<00:00, 44991.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGLg6udky1zo",
        "colab_type": "text"
      },
      "source": [
        "You can add more features to the feature matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80GgEm6F5DG",
        "colab_type": "code",
        "outputId": "28c7ea87-f577-4f5b-e358-9bc479039a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYOUR CODE GOES HERE\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtm7a6JWu9-3",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "We train logistic regression model and save prediction for train, val and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9stSAbAIZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "\n",
        "# Fit the model to training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction using the trained model\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-Abw7JOqD_",
        "colab_type": "text"
      },
      "source": [
        "## Performance of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akg9LvP5DGE8",
        "colab_type": "text"
      },
      "source": [
        "Your task is to report train, val, test accuracies and F1 scores.\n",
        "**You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.**\n",
        "\n",
        "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chqVbKH6kZyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(y_true, y_pred): \n",
        "    # Calculate accuracy of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    accuracy = sum(y_true == y_pred)/y_pred.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "def f1_score(y_true, y_pred): \n",
        "    # Calculate F1 score of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)): \n",
        "        if y_true[i]==y_pred[i]==1:\n",
        "           TP += 1\n",
        "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
        "           FP += 1\n",
        "        if y_true[i]==y_pred[i]==0:\n",
        "           TN += 1\n",
        "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
        "           FN += 1\n",
        "\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqrMw0udDD04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "26a672f7-42f1-46bc-9ed1-5d1a031feee6"
      },
      "source": [
        "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
        "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
        "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.997, F1 score: 0.990\n",
            "Validation accuracy: 0.974, F1 score: 0.902\n",
            "Test accuracy: 0.984, F1 score: 0.938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW7P84giGgP4",
        "colab_type": "text"
      },
      "source": [
        "**Question.**\n",
        "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
        "\n",
        "**Your answer:** Logistic regression optimizes the cross-entropy loss, thus accuracy is being optimized, as 1-1 and 0-0, predictions that match with ground truth, have 0 loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak0h71krLPqX",
        "colab_type": "text"
      },
      "source": [
        "**Question.**\n",
        "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
        "\n",
        "**Your answer:** 0.99 accuracy does not mean necessarily a great model. For example, in cancer detection, we care more about recall than accuracy, since we do not want to miss out a cancer on any patient (do not want false negatives). In this case, a high accuracy is not as important as good recall. Missing out diagnosing a cancer is more distractous than wrongly predicting someone to have cancer when he/she actually does not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_RDI0qdOxwM",
        "colab_type": "text"
      },
      "source": [
        "### Exploration of predicitons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHR2OqYCDOxs",
        "colab_type": "text"
      },
      "source": [
        "Show a few examples with true+predicted labels on the train and val sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yv8GD-UGXvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "820e0d48-3065-4125-f924-42f1480b7d79"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "# 1 - spam, 0 - ham\n",
        "\n",
        "print(\"First 10 training labels:\\n\",\"Predictions: \",y_train_pred[:10],\"\\n Truth: \",y_train[:10])\n",
        "print(\"First 10 validation labels:\\n\",\"Predictions: \",y_val_pred[:10],\"\\n Truth: \",y_val[:10])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 training labels:\n",
            " Predictions:  [0 0 1 0 0 1 0 0 1 1] \n",
            " Truth:  [0 0 1 0 0 1 0 0 1 1]\n",
            "First 10 validation labels:\n",
            " Predictions:  [0 1 1 0 0 0 0 0 0 1] \n",
            " Truth:  [0 1 1 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neMQ4VR9GVL3",
        "colab_type": "text"
      },
      "source": [
        "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
        "\n",
        "**Your answer:** Since BoW model only cares about occurence of words instead of the actual ordering of any sentence, it is very likely that it will perform worse on sentences with spam-like words but are not actually spam. For example, \"cat loves to eat mouse\" and \"mouse loves to eat cat\" actually are regarded the same by BoW model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ssK0jRxGY3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "1a9b02bf-91f3-4c2e-df71-fdbf7b19099e"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "\n",
        "indices = (y_val_pred != y_val).nonzero()[0].tolist()[:10]\n",
        "for index in indices:\n",
        "  print(\"Text: \",val_texts.iloc[index])\n",
        "  print(\"Predicted: \", \"spam\" if y_val_pred[index] else \"ham\")\n",
        "  print(\"Truth: \",\"spam\" if y_val[index] else \"ham\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  ringtoneking 84484\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  You will be receiving this week's Triple Echo ringtone shortly. Enjoy it!\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  Win a å£1000 cash prize or a prize worth å£5000\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  TBS/PERSOLVO. been chasing us since Sept forå£38 definitely not paying now thanks to your information. We will ignore them. Kath. Manchester.\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  Loans for any purpose even if you have Bad Credit! Tenants Welcome. Call NoWorriesLoans.com on 08717111821\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  In The Simpsons Movie released in July 2007 name the band that died at the start of the film? A-Green Day, B-Blue Day, C-Red Day. (Send A, B or C)\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  Sorry, it's a lot of friend-of-a-friend stuff, I'm just now about to talk to the actual guy who wants to buy\n",
            "Predicted:  spam\n",
            "Truth:  ham\n",
            "\n",
            "\n",
            "Text:  Missed call alert. These numbers called but left no message. 07008009200\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  accordingly. I repeat, just text the word ok on your mobile phone and send\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n",
            "Text:  Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA\n",
            "Predicted:  ham\n",
            "Truth:  spam\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja1hoUIFp_C2",
        "colab_type": "text"
      },
      "source": [
        "## End of Part 1.\n"
      ]
    }
  ]
}